<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css?family=Arsenal" rel="stylesheet">
  <link rel="stylesheet" href="static/style.css">
  <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-NM97KQJ');</script>
<!-- End Google Tag Manager -->
  <script src="static/script.js"></script>
  <title>Thomas Dybdahl Ahle</title>
</head>
<body>
   <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-337734-4', 'auto');
  ga('send', 'pageview');

</script>
   <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NM97KQJ"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
   <h1>Thomas Dybdahl Ahle</h1>
   <div id='main'>
      <p>
         Hi, I'm Thomas. I am a graduate student in Theoretical Computer Science with <a href='https://www.itu.dk/people/pagh/'>Rasmus Pagh</a> at the IT University of Copenhagen,
         and a researcher at <a href='https://barc.ku.dk/'>Basic Algorithms Research Copenhagen</a>.
        Previously I have been at University of Texas at Austin, and University of Oxford.
        <!--where my advisors were <a href='https://www.cs.ox.ac.uk/samson.abramsky/'>Samson Abramsky</a> and <a href='https://www.cs.ox.ac.uk/people/oege.demoor/'>Oege de Moor</a>.-->
      </p><p>
        My research has primarily involved the theoretical foundations of massive data, similarity search (which is also my primary funding through <a href='http://sss.projects.itu.dk/'>Scalable Similarity Search</a>), high dimensional geometry, sketching and derandomization.
        See also my <a href='statement.pdf'>research program</a>.
      </p>

      <h2>News</h2>
      <dl>
         <dt>1/feb/19</dt>
         <dd>The date for handing in my PhD. is now set at April 1st.
               I am interested in hearing about Post Doc positions anywhere in the world.
         </dd>
         <dt>1/oct/18</dt>
         <dd>I have decided to leave SupWiz and return to Academia.
            Looking forward to work with everyone!
         </dd>
         <dt>1/sep/18</dt>
         <dd>I am taking a 1 year sabatical to start up a new Machine Learning company, <a href='https://supwiz.com'>SupWiz</a>, with former research collegues.
         </dd>
      </dl>

      <h2>Publications</h2>
      <ul id="publications"><li>
            <div class='shown' id='paper-tensorsketch2'>TA, <a href='https://di.ku.dk/english/staff/?pure=en/persons/493157'>J Knudsen</a> —
               2019<br />
               <strong>High Probability Tensor Sketch</strong>.
               Submitted,
               (<a href='papers/tensorsketch2.pdf'
                     onclick="dataLayer.push({'event': 'download_tensorsketch2_pdf'});"
                     >pdf</a>)
            </div>
            <div class='abstract'>We construct a structured Johnson Lindenstrauss transformation that can be applied to simple tensors on the form x = x^(1) ⊗ ... ⊗ x^(c) ∈ ℝ^(dᶜ)$ in time nearly c⋅d.
That is, exponentially faster than writing out the Kronecker product and then mapping down.

These matrices, M, which preserves the norm of any x ∈ ℝ^(d^c), such that | ||Mx||₂ - ||x||₂ | < ε with probability  1-δ , can be taken to have just  Õ(c² ε⁻² (log1/δ)³)  rows.
This is within c² (\log1/δ)²  of optimal for any JL matrix [Larsen & Nelson], and improves upon earlier 'Tensor Sketch' constructions by Pagh and Pham, which used  Õ(3ᶜ ε⁻² δ⁻¹)  rows, by an exponential amount in both  c  and  δ⁻² .

It was shown by Avron, Nguyen and Woodruff that Tensor Sketch is a subspace embedding.
This has a large number of applications, such as guaranteeing the correctness of kernel-linear regression performed directly on the reduced vectors.
We show that our construction is a subspace embedding too, improving again upon the exponential dependency on  c  and  δ⁻¹ , enabling sketching of much higher order polynomial kernels, such as Taylor approximations to the ubiquitous Gaussian radial basis function.

Technically, we construct our matrix  M  such that  M(x ⊗ y) = Tx ∘ T'y  where  ∘  is the Hadamard (element-wise) product and  T  and  T'  support fast matrix-vector multiplication ala [Ailon Chazelle].
To analyze the behavior of  Mx  on non-simple  x , we show a higher order version of Khintchine's inequality, related to the higher order Gaussian chaos analysis by Latała.
Finally we show that such sketches can be combined recursively, in a way that doesn't increase the dependency on  c  by much.
</div>
         </li><li>
            <div class='shown' id='paper-lasvegas'>TA —
               2017, <span class="comment">Updated Jun 2018</span><br />
               <strong>Optimal Las Vegas Locality Sensitive Data Structures</strong>.
               Foundations of Computer Science,
               (<a href='papers/lasvegas.pdf'
                     onclick="dataLayer.push({'event': 'download_lasvegas_pdf'});"
                     >pdf</a>, <a href='http://arxiv.org/abs/1704.02054'
                     onclick="dataLayer.push({'event': 'download_lasvegas_arxiv'});"
                     >arxiv</a>, <a href='https://docs.google.com/presentation/d/1HgNCrDFdIZ_oh2RRedmd1qOHgWxk74HSkUCMGcuUbP8/edit?usp=sharing'
                     onclick="dataLayer.push({'event': 'download_lasvegas_slides'});"
                     >slides</a>)
            </div>
            <div class='abstract'>We show that approximate similarity (near neighbour) search can be solved in high dimensions with performance matching state of the art (data independent) Locality Sensitive Hashing, but with a guarantee of no false negatives.
Specifically we give two data structures for common problems.
For c-approximate near neighbour in Hamming space, for which we get query time dn^{1/c+o(1)} and space dn^{1+1/c+o(1)} matching that of [Indyk and Motwani, 1998] and answering a long standing open question from [Indyk, 2000a] and [Pagh, 2016] in the affirmative.
For $(s1,s2)$-approximate Jaccard similarity we get query time d^2n^{ρ+o(1)} and space d^2n^{1+ρ+o(1)}, ρ= [log (1+s1)/(2s1)]/[log (1+s2)/(2s2)], when sets have equal size, matching the performance of [Pagh and Christiani, 2017].

We use space partitions as in classic LSH, but construct these using a combination of brute force, tensoring and splitter functions à la [Naor et al., 1995].
We also show two dimensionality reduction lemmas with 1-sided error.
</div>
         </li><li>
            <div class='shown' id='paper-output-sensitive'>TA, <a href='http://itu.dk/people/maau/'>M Aumüller</a>, <a href='https://www.itu.dk/people/pagh/'>R Pagh</a> —
               2017<br />
               <strong>Parameter-free Locality Sensitive Hashing for Spherical Range Reporting</strong>.
               Proceedings of Symposium on Discrete Algorithms,
               (<a href='papers/output-sensitive-lsh-for-knn.pdf'
                     onclick="dataLayer.push({'event': 'download_output-sensitive_pdf'});"
                     >pdf</a>, <a href='http://arxiv.org/abs/1605.02673'
                     onclick="dataLayer.push({'event': 'download_output-sensitive_arxiv'});"
                     >arxiv</a>, <a href='https://docs.google.com/presentation/d/1UOFCN1Eujr4sCQdYqdwn_8D8pNCJHEyzw9Yd_BW6bh4'
                     onclick="dataLayer.push({'event': 'download_output-sensitive_slides'});"
                     >slides</a>)
            </div>
            <div class='abstract'>We present a data structure for <i>spherical range reporting</i> on a point set S, i.e., reporting all points in S that lie within radius r of a given query point q. Our solution builds upon the Locality-Sensitive Hashing (LSH) framework of Indyk and Motwani, which represents the asymptotically best solutions to near neighbor problems in high dimensions. While traditional LSH data structures have several parameters whose optimal values depend on the distance distribution from q to the points of S, our data structure is parameter-free, except for the space usage, which is configurable by the user. Nevertheless, its expected query time basically matches that of an LSH data structure whose parameters have been <i>optimally chosen for the data and query</i> in question under the given space constraints. In particular, our data structure provides a smooth trade-off between hard queries (typically addressed by standard LSH) and easy queries such as those where the number of points to report is a constant fraction of S, or where almost all points in S are far away from the query point. In contrast, known data structures fix LSH parameters based on certain parameters of the input alone.
<br/>The algorithm has expected query time bounded by O(t(n/t)^ρ), where t is the number of points to report and ρ∈(0,1) depends on the data distribution and the strength of the LSH family used. We further present a parameter-free way of using multi-probing, for LSH families that support it, and show that for many such families this approach allows us to get expected query time close to O(n^ρ+t), which is the best we can hope to achieve using LSH. The previously best running time in high dimensions was Ω(tn^ρ). For many data distributions where the intrinsic dimensionality of the point set close to q is low, we can give improved upper bounds on the expected query time.
</div>
         </li><li>
            <div class='shown' id='paper-mips'>TA, <a href='https://www.itu.dk/people/pagh/'>R Pagh</a>, <a href='http://www.ilyaraz.org/'>I Razenshteyn</a>, <a href='http://www.dei.unipd.it/~silvestri/'>F Silvestri</a> —
               2016<br />
               <strong>On the Complexity of Inner Product Similarity Join</strong>.
               Symposium on Principles of Database Systems,
               (<a href='papers/mips/paper.pdf'
                     onclick="dataLayer.push({'event': 'download_mips_pdf'});"
                     >pdf</a>, <a href='http://arxiv.org/abs/1510.02824'
                     onclick="dataLayer.push({'event': 'download_mips_arxiv'});"
                     >arxiv</a>, <a href='https://docs.google.com/presentation/d/1y_BZ5Ctyn67Vam8rWzrskMkrkc-yIelCQsFLz1g4_bM'
                     onclick="dataLayer.push({'event': 'download_mips_slides'});"
                     >slides</a>)
            </div>
            <div class='abstract'>A number of tasks in classification, information retrieval, recommendation systems, and record linkage reduce to the core problem of inner product similarity join (IPS join): identifying pairs of vectors in a collection that have a sufficiently large inner product. IPS join is well understood when vectors are normalized and some approximation of inner products is allowed. However, the general case where vectors may have any length appears much more challenging. Recently, new upper bounds based on asymmetric locality-sensitive hashing (ALSH) and asymmetric embeddings have emerged, but little has been known on the lower bound side. In this paper we initiate a systematic study of inner product similarity join, showing new lower and upper bounds. Our main results are: 
<br/>* Approximation hardness of IPS join in subquadratic time, assuming the strong exponential time hypothesis. 
<br/>* New upper and lower bounds for (A)LSH-based algorithms. In particular, we show that asymmetry can be avoided by relaxing the LSH definition to only consider the collision probability of distinct elements. 
<br/>* A new indexing method for IPS based on linear sketches, implying that our hardness results are not far from being tight. 
<br/>Our technical contributions include new asymmetric embeddings that may be of independent interest. At the conceptual level we strive to provide greater clarity, for example by distinguishing among signed and unsigned variants of IPS join and shedding new light on the effect of asymmetry.
</div>
         </li></ul>

      <h2>Media</h2>
      <ul><li><a href='http://www.stibo.com/da/2016/08/26/the-stibo-foundation-supports-it-talents/'>Stibo</a> - August 2016.<br/>The announcement of my winning the Stibo Travel grant.</li><li><a href='http://www.pressreader.com/australia/linux-format/20151222/282802125292910'>Pressreader</a> - December 2015.<br/>A article about my Sunfish chess software.</li><li><a href='http://www.computerworld.dk/art/234196'>Computerworld</a> - June 2015.<br/>Coverage of my teams participation in the ICPC World Finals.</li></ul>

      <h2>Code</h2>
      <ul>
         <li><a href='https://github.com/thomasahle/mtime'>mtime</a> - helps managing the ITU time management</li>
         <li><a href='http://pychess.org/'>PyChess</a> - a chess engine and Internet chess client</li>
         <li><a href='https://github.com/thomasahle/sunfish'>Sunfish</a> - a minimalist chess engine</li>
         <li><a href='https://github.com/thomasahle/numberlink'>numberlink</a> - a fast solver for numberlink puzzles</li>
         <li><a href='https://github.com/thomasahle/codenames'>codenames</a> - an AI that plays Codenames using Glove vectors.
         <li><a href='https://github.com/thomasahle/fastchess'>fastchess</a> - an experiment into using the Fasttext library to play chess.
      </ul>

   </div>
   <div id='side'>
      <img src='static/thomas_farve.png' alt='A photo of me' id='me'/>
      <h3>Coauthors</h3>
      <ul><li><a href='http://itu.dk/people/maau/'>Martin Aumüller</a></li><li><a href='https://di.ku.dk/english/staff/?pure=en/persons/493157'>Jakob Bæk Tejs Knudsen</a></li><li><a href='https://www.itu.dk/people/pagh/'>Rasmus Pagh</a></li><li><a href='http://www.ilyaraz.org/'>Ilya Razenshteyn</a></li><li><a href='http://www.dei.unipd.it/~silvestri/'>Francesco Silvestri</a></li></ul>

      <h3>Contact</h3>
      <ul>
         <li><a href='https://ahlenotes.wordpress.com/' title='My blog'>Blog</a></li>
         <li>Email: thdy@itu.dk</li>
         <li><a href='https://linkedin.com/in/thomasahle'>Linkedin</a></li>
         <li><a href='cv.pdf'>CV</a></li>
         <li><a href='statement.pdf'>Academic Statement</a></li>
      </ul>
   </div>
</body>
</html>

