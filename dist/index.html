<!DOCTYPE html>
<html lang="en-GB">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="thumbnail" content="/static/potrait.jpg" />

  <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>
  <link rel="preconnect" href="https://www.google-analytics.com/" crossorigin>

  <link rel="icon" type="image/x-icon" href="/static/favicon_io/favicon-16x16.png" sizes="16x16" />
  <link rel="icon" type="image/x-icon" href="/static/favicon_io/favicon-32x32.png" sizes="32x32"/>
  <link rel="icon" type="image/x-icon" href="/static/favicon_io/favicon.ico" sizes="48x48" />
  <link rel="icon" type="image/x-icon" href="/static/favicon_io/android-chrome-192x192.png" sizes="192x192" />

  <link href="https://fonts.googleapis.com/css?family=Lato:300,400,500|Cardo:400,400i&display=fallback" rel="stylesheet">
  <!--&display=swap-->

  
  <style type="text/css">:root {
   --border-radius: 4px;
   --fonts: Lato, Helvetica Neue, sans-serif;
   --toggle-size: 25px;
}
body {
  font-family: sans-serif;
  font-family: var(--fonts);
  font-size: 1rem;
  font-weight: 300;
  padding: 1rem .33rem;
  line-height: 1.55;
  max-width: 50em;
  margin-left: auto;
  margin-right: auto;
  display: flex;
  flex-flow: row wrap;
  background: #fcfcfc;

  hyphens: auto;
  -ms-hyphens: auto;
  -webkit-hyphens: auto;
  text-rendering: optimizeLegibility;
}
h1 {
   flex: 1 100%;
   font-size: 2em;
}
h2, h3 {
   margin-bottom: 0;
   line-height: 1;
}
h2 {
   font-size: 1.5em;
}
h3 {
   font-size: 1.167em;
}
h1, h2, h3 {
   font-weight: 500;
}
#main {
   flex: 2.618 16rem;
}
#main p:first-child {
   margin-top: 0;
}
#side {
   flex: 1 7rem;
}
h1 {
   margin: 1rem .67rem 1rem .66rem;
  /*margin-left: .66rem;
  margin-right: .67rem;*/
}
h2 {
   margin-top: 1.5rem;
}
#main, #side {
  margin: 0 .66rem 2rem .67rem;
}
ul {
   list-style-type: none;
   padding: 0;
}
dd {
   font-style: italic;
   margin-left: 2em;
}
.toggle-item {
   border: 1px solid rgba(0,0,0,.1);
   /*box-shadow: 0px 3px 2px -2px rgba(0,0,0,.05);*/
   border-radius: 2px;
   border-radius: var(--border-radius);
   margin-bottom: 10px;
   /*background: #fdfdfd;*/
   background: white;
   box-shadow: 0px 4px 4px -3px rgba(0,0,0,.1);
}
.toggle-item:hover {
   /*box-shadow: 0px 1px 2px 0px rgba(0,0,0,.1);*/
}
.toggle-item:active {
   background: #fafafa;
   box-shadow: 0px 4px 4px -3px rgba(0,0,0,.2);
}
.shown {
   padding: 8px 6%;
   text-align: center;
}
.shown .year {
   display: block;
   text-align: left;
}
.shown .files {
   float: right;
   text-align: right;
}
.files, .year, .authors {
   font-size: 90%;
}
.shown .title {
   hyphens: none;
   margin-top: .5rem;
   display: block;
   font-weight: 400;
   clear: both;
}
.abstract {
   /*border-top: 1px solid rgba(0,0,0,.1);*/
   padding: 0px 6% 1em 6%;
   position: relative;
   font-family: 'Latin Modern Roman', 'Latin Modern', Cardo, Garamond, serif;
   text-align: justify;
   line-height: 1.15;
}
.abstract p {
   text-indent: 1em;
   margin: 0;
}
.abstract p:first-child {
   text-indent: 0;
}
.toggle-item:not(.open) .abstract {
   max-height: 14ch;
   line-height: 1.1;
   overflow:hidden;
   font-style: italic;
   font-size: .85rem;
   cursor: pointer;
}
.abstract:before {
   position: absolute;
   font-style: normal;
   cursor: pointer;
   color: black;
   bottom: 0; right: 0;
   z-index: 1;
   background: white;
   padding: 8px 10px 8px 10px;
   font-family: var(--fonts);
   border-radius: var(--border-radius);
   font-size: .85rem;
}
.toggle-item:not(.open) .abstract:before {
   content: "View Abstract ⌵";
}
/*.abstract:target{
   padding-bottom: 20px;
}*/
.toggle-item.open .abstract:before {
   margin-top:10px;
   content: "Hide Abstract ⌃";
}
.toggle-item:not(.open) .abstract {
   color: #222;
}
.toggle-item:not(.open) .abstract:after {
   content: " ";
   position: absolute;
   left: 0; right: 0; top: 0; bottom: 0;
   background: linear-gradient(180deg, rgba(255,255,255,0) 60%, rgba(255,255,255,1) 100%);
   border-radius: var(--border-radius);
}
#side li {
  display: block;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}
img {
   width: 26.18vw;
   height: 26.18vw;
   max-width: 12rem;
   max-height: 12rem;
}
sub,
sup {
   /**
    * Prevent `sub` and `sup` affecting `line-height` in all browsers.
    */
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
a {
   text-decoration: none;
   color: #0645ad;
}
a:visited {
   color: #0b0080;
}
a:hover {
   text-decoration: underline;
   text-decoration-skip:ink;
   -webkit-text-decoration-skip:ink;
   -moz-text-decoration-skip:ink;
   /*text-decoration-color: #008;*/
   /*text-decoration-color: #aad;*/
   /*-webkit-text-decoration-color: #aad;
   -moz-text-decoration-color: #aad;*/
}
.comment {
   font-style: italic;
}
@media only screen and (max-width: 500px) {
  .toggle-item {
     margin-left: -1rem;
     margin-right: -1rem;
  }
  #me {
     width: 13rem;
     height: 13rem;
  }
}
/********** Toggle **********/
input[type=checkbox]{
   display: none;
}

#show-all {
   float: right;
   margin-top: .15em;
}

label {
   cursor: pointer;
   font-size: 1.5em;
}

.toggle {
   display: inline-block;
   background: grey;
   text-indent: calc(var(--toggle-size) * 2 + 1em);
   width: calc(var(--toggle-size) * 2);
   height: calc(var(--toggle-size) * 1);
   border-radius: calc(var(--toggle-size) * 1);
   position: relative;
   vertical-align: text-bottom;
}

.toggle-text {
   padding-right: .3em;
}

.toggle:after {
   content: '';
   position: absolute;
   top: 1px;
   left: 1px;
   width: calc(var(--toggle-size) - 2px);
   height: calc(var(--toggle-size) - 2px);
   background: #fff;
   border-radius: calc(var(--toggle-size) - 2px);
   transition: 0.3s;
}

input:checked + .toggle {
   background: #5a8bff;
}

input:checked + .toggle:after {
   left: calc(100% - var(--toggle-size) * .05);
   transform: translateX(-100%);
}

input:active + .toggle:after {
   width: calc(var(--toggle-size) * 1.2);
}

.publications.toggled .toggle-item:not(.featured) {
   display: none;
}
/*
 * Use animation?
.publications:not(.toggled) .toggle-item:not(.featured) {
    opacity: 0;
    max-height: 0;
}
.publications .toggle-item {
    opacity: 1;
    max-height: 1000px;
    transition: max-height 600ms 0ms, opacity 300ms 300ms;
}
*/</style>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-166937336-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-166937336-1', {
    //'storage': 'none',
    'client_storage': 'none',
    //'cookie_expires': 0,
    //'anonymize_ip': true
  });
</script>
   
  
  <script type="application/javascript">function addLoadEvent(func) {
  var oldonload = window.onload;
  if (typeof window.onload != 'function') {
    window.onload = func;
  } else {
    window.onload = function() {
      if (oldonload) {
        oldonload();
      }
      func();
    }
  }
}
// External links
addLoadEvent(function() {
   for (let a of document.querySelectorAll('a[href^="http"]')) {
      // :not([href*="//' + location.host + '"])')
      a.addEventListener('click', event => {
         gtag('event', 'click', {
            'event_category': 'outbound',
            'event_label': a.href,
            'transport_type': 'beacon'
            /*'hitCallback': function() { document.location = a.href; }*/
         });
         //return false;
      });
   }
});</script>

  <script type="application/ld+json">
   {"@context" : "http://schema.org",
    "@type" : "CollectionPage",
     "author": {
          "@type": "Person",
          "name": "Thomas Dybdahl Ahle",
           "image": [ "https://thomasahle.com/static/potrait.jpg" ],
           "spouse": {
                "@type": "Person",
                "name": "Morgan Mingle"
           }
     },
     "image": [ "https://thomasahle.com/static/potrait.jpg" ],
     "primaryImageOfPage": "https://thomasahle.com/static/potrait.jpg",
     "thumbnailUrl": "https://thomasahle.com/static/potrait.jpg" 
     }
   </script>

  <script type="application/javascript">
addLoadEvent(function () {
   /* Show hide abstracts */
   for (let div of document.querySelectorAll('.toggle-item')) {
      div.onclick = function() {
          // Other options: event_category, event_label, value (numeric)
          gtag('event', 'toggle', {'event_label': div.id});
          this.classList.toggle('open');
          window.history.replaceState(null, null, '#'+div.id);
      }
      if ('#'+div.id == window.location.hash) {
         div.classList.add('open');

      }
      // TODO: If hash paper is not featured, we should enable show-all
   }

   /* Show hide featured */
   let toggle = () => {
      for (let div of document.querySelectorAll('.publications')) {
         div.classList.toggle('toggled');
      }
   }
   let checkbox = document.getElementById('show-all-checkbox');
   checkbox.addEventListener('change', event => {
      gtag('event', 'toggle-show-all', {'event_label': event.target.checked ? 'on' : 'off' });
      toggle();
   });
   // If hash, we should show all, in case the hashed paper is hidden
   if (window.location.hash)
      checkbox.checked = true;
   if (!checkbox.checked)
      toggle();

   /* Mouse over me */
   let img = document.getElementById('me');
   img.onmouseover = function() {
     img.setAttribute('src', '/static/water.jpg');
     gtag('event', 'hover_me', {'event_label': 'on'});
   }
   img.onmouseout = function() {
     img.setAttribute('src', '/static/potrait.jpg');
     gtag('event', 'hover_me', {'event_label': 'off'});
   }
});
  </script>
  <title>Thomas Dybdahl Ahle</title>
</head>
<body>
   <h1>Thomas Dybdahl Ahle</h1>
   <div id='main'>
      <p>
         Hello, I'm Thomas.
         I am an Algorithms Research Scientist at Facebook.
         Pre&shy;vi&shy;ously I was the Chief of Machine Learning at the Natural Language Processing startup, <a href='https://supwiz.com'>SupWiz</a>,
         and a Postdoctoral researcher in Theoretical Computer Sci&shy;ence at the <a href='https://barc.ku.dk/'>Basic Algorithms Research</a> group (BARC) in Copenhagen.
         I did my PhD with <a href='https://www.itu.dk/people/pagh/'>Rasmus Pagh</a> on the <a href='http://sss.projects.itu.dk/'>Scalable Similarity Search</a> project, and
        previously I have been at University of Texas at Austin, and University of Oxford.
        <!--where my advisors were <a href='https://www.cs.ox.ac.uk/samson.abramsky/'>Samson Abramsky</a> and <a href='https://www.cs.ox.ac.uk/people/oege.demoor/'>Oege de Moor</a>.-->
      </p><p>
        My research has primarily involved the theoretical foundations of machine learning and massive data.
        This includes similarity search, high dimensional geometry, kernel methods, sketching and derandomization.
      </p>

      <div id='show-all'>
         <label for="show-all-checkbox" class='toggle-text'>Show All</label>
         <input type="checkbox" id="show-all-checkbox"i checked />
         <label for="show-all-checkbox" class='toggle'></label>
      </div>
      
         <h2>Publications</h2>
         <ul class="publications"><li class="toggle-item "
                  id='paper-mersenne'>
               <div class='shown'>
                  <span class='files'>[<a href='papers/mersenne.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_mersenne_pdf'});"
                        >pdf</a>]</span>

                  <span class='year'>In Review
                  
                  2020</span>

                  
                  <span class='title'>The Power of Hashing with Mersenne&nbsp;Primes</span>
                  

                  <span class='authors'>
                  TA, <a href='https://di.ku.dk/english/staff/?pure=en/persons/493157'
                           onclick="gtag('event', 'coauthor', {'event_label': 'J Knudsen'});"
                           >J Knudsen</a>, <a href='http://hjemmesider.diku.dk/~mthorup/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'M Thorup'});"
                           >M Thorup</a>
                  </span>
               </div>
               <div class='abstract'><p>The classic way of computing a k-universal hash function is to use a random degree-(k−1) polynomial over a prime field ℤ<sub>p</sub>. For a fast computation of the polynomial, the prime p is often chosen as a Mersenne prime p = 2<sup>b</sup>−1.
</p><p>
In this paper, we show that there are other nice advantages to using Mersenne primes. Our view is that the output of the hash function is a b-bit integer that is uniformly distributed in [2<sup>b</sup>], except that p (the all 1s value) is missing. Uniform bit strings have many nice properties, such as splitting into substrings which gives us two or more hash functions for the cost of one, while preserving strong theoretical qualities. We call this trick “Two for one” hashing, and we demonstrate it on 4-universal hashing in the classic Count Sketch algorithm for second moment estimation.
</p><p>
We also provide a new fast branch-free code for division and modulus with Mersenne primes. Contrasting our analytic work, this code generalizes to Pseudo-Mersenne primes p = 2<sup>b</sup>−c for small c, improving upon a classical algorithm of Crandall.
</p>
</div>
            </li><li class="toggle-item "
                  id='paper-tcu'>
               <div class='shown'>
                  <span class='files'>[<a href='https://arxiv.org/abs/2006.12608'
                        onclick="gtag('event', 'download', {'event_label': 'download_tcu_arxiv'});"
                        >arxiv</a>]  [<a href='papers/tcu.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_tcu_pdf'});"
                        >pdf</a>]</span>

                  <span class='year'>SISAP
                  2020</span>

                  
                  <span class='title'>Similarity Search with Tensor Core Units</span>
                  

                  <span class='authors'>
                  TA, <a href='http://www.dei.unipd.it/~silvestri/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'F Silvestri'});"
                           >F Silvestri</a>
                  </span>
               </div>
               <div class='abstract'><p>Tensor Core Units (TCUs) are hardware accelerators developed for deep neural networks, which efficiently support the multiplication of two dense √m × √m matrices, where m is agiven hardware parameter.
In this paper, we show that TCUs can speed up similarity searchproblems  as  well.   We  propose  algorithms  for  the  Johnson-Lindenstrauss  dimensionality reduction and for similarity join that, by leveraging TCUs, achieve a √m speedup up with respect to traditional approaches.
</p>
</div>
            </li><li class="toggle-item "
                  id='paper-p1'>
               <div class='shown'>
                  <span class='files'>[<a href='https://arxiv.org/abs/2005.12065'
                        onclick="gtag('event', 'download', {'event_label': 'download_p1_arxiv'});"
                        >arxiv</a>]  [<a href='papers/p1.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_p1_pdf'});"
                        >pdf</a>]</span>

                  <span class='year'>SISAP
                  2020</span>

                  
                  <span class='title'>On the Problem of p₁⁻¹ in Locality‑Sensitive&nbsp;Hashing</span>
                  

                  <span class='authors'>
                  TA
                  </span>
               </div>
               <div class='abstract'><p>A Locality-Sensitive Hash (LSH) function is called (r,cr,p<sub>1</sub>,p<sub>1</sub>)-sensitive, if two data-points with a distance less than r collide with probability at least p<sub>1</sub> while data points with a distance greater than cr collide with probability at most p<sub>2</sub>.
These functions form the basis of the successful Indyk-Motwani algorithm (STOC 1998) for nearest neighbour problems.
In particular one may build a c-approximate nearest neighbour data structure with query time O(n<sup>ρ</sup>/p₁) where ρ = (log 1/p<sub>1</sub>)/(log 1/p<sub>2</sub>) ∈ (0,1).
That is, <em>sub-linear time</em>, as long as p<sub>1</sub> is not too small.
This is significant since most high dimensional nearest neighbour problems suffer from the curse of dimensionality, and can't be solved <em>exact</em>, faster than a brute force <em>linear-time</em> scan of the database.
</p><p>
Unfortunately, the best LSH functions tend to have very low collision probabilities, p<sub>1</sub> and p<sub>2</sub>.
Including the best functions for Cosine and Jaccard Similarity.
This means that the n<sup>ρ</sup>/p<sub>1</sub> query time of <em>LSH is often not sub-linear after all</em>, even for approximate nearest neighbours!
</p><p>
In this paper, we improve the general Indyk-Motwani algorithm to reduce the query time of LSH to O(n<sup>ρ</sup>/p<sub>1</sub><sup>1-ρ</sup>) (and the space usage correspondingly.)
Since  n<sup>ρ</sup>/p<sub>1</sub><sup>1-ρ</sup> < n ⇔ p<sub>1</sub> > 1/n,
our algorithm always obtains sublinear query time, for all collision probabilities at least  1/n.
For  p<sub>1</sub>  and  p<sub>2</sub>  small enough, our improvement over all previous methods can be <em>up to a factor  n </em> in both query time and space.
</p><p>
The improvement comes from a simple change to the Indyk-Motwani algorithm, which can easily be implemented in existing software packages.
</p>
</div>
            </li><li class="toggle-item featured"
                  id='paper-supermajority'>
               <div class='shown'>
                  <span class='files'>[<a href='http://arxiv.org/abs/1904.04045'
                        onclick="gtag('event', 'download', {'event_label': 'download_supermajority_arxiv'});"
                        >arxiv</a>]  [<a href='https://thomasahle.com/blog/sets.html'
                        onclick="gtag('event', 'download', {'event_label': 'download_supermajority_blog post'});"
                        >blog post</a>]  [<a href='papers/supermajority.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_supermajority_pdf'});"
                        >pdf</a>]  [<a href='https://docs.google.com/presentation/d/1qB4M7oEHmeRs8b0x1u0O3NS7PozydhVgqI059Bi_2QE'
                        onclick="gtag('event', 'download', {'event_label': 'download_supermajority_slides'});"
                        >slides</a>]</span>

                  <span class='year'>FOCS
                  2020</span>

                  
                  <span class='title'>Subsets and Supermajorities: Optimal&nbsp;Hashing‑based Set&nbsp;Similarity&nbsp;Search</span>
                  

                  <span class='authors'>
                  TA, <a href='https://di.ku.dk/english/staff/?pure=en/persons/493157'
                           onclick="gtag('event', 'coauthor', {'event_label': 'J Knudsen'});"
                           >J Knudsen</a>
                  </span>
               </div>
               <div class='abstract'><p>
We formulate and optimally solve a new generalized Set Similarity Search problem,
which assumes the size of the database and query sets are known in advance.
By creating polylog copies of our data-structure, we optimally solve any symmetric Approximate Set Similarity Search problem, including approximate versions of Subset Search, Maximum Inner Product Search (MIPS), Jaccard Similarity Search and Partial Match.
</p>

<p>
Our algorithm can be seen as a natural generalization of previous work on Set as well as Euclidean Similarity Search, but conceptually it differs by optimally exploiting the information present in the sets as well as their complements, and doing so asymmetrically between queries and stored sets.
Doing so we improve upon the best previous work:
MinHash [J. Discrete Algorithms 1998], SimHash [STOC 2002], Spherical LSF
[SODA 2016, 2017] and Chosen Path [STOC 2017] by as much as a factor n<sup>.14</sup> in both time and space; or in the near-constant time regime, in space, by an arbitrarily large polynomial factor.
</p>

<p>
Turning the geometric concept, based on Boolean supermajority functions, into a practical algorithm requires ideas from branching random walks on Z<sup>2</sup>, for which we give the first non-asymptotic near tight analysis.
</p>

<p>
Our lower bounds follow from new hypercontractive arguments, which can be seen as characterizing the exact family of similarity search problems for which supermajorities are optimal.
The optimality holds for among all hashing based data structures in the random setting, and by reductions, for 1 cell and 2 cell probe data structures.
As a side effect, we obtain new hypercontractive bounds on the directed noise operator.
</p>
</div>
            </li><li class="toggle-item featured"
                  id='paper-tensorsketch-joint'>
               <div class='shown'>
                  <span class='files'>[<a href='https://arxiv.org/abs/1909.01410'
                        onclick="gtag('event', 'download', {'event_label': 'download_tensorsketch-joint_arxiv'});"
                        >arxiv</a>]  [<a href='papers/tensorsketch-joint.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_tensorsketch-joint_pdf'});"
                        >pdf</a>]  [<a href='papers/TensorSketch_Amir.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_tensorsketch-joint_slides'});"
                        >slides</a>]</span>

                  <span class='year'>SODA
                  2020
                     —
                     <span class="comment">Merged from "Almost Optimal Tensor&nbsp;Sketch"</span></span>

                  
                  <span class='title'>Oblivious Sketching of High‑Degree&nbsp;Polynomial&nbsp;Kernels</span>
                  

                  <span class='authors'>
                  TA, <a href='https://theory.epfl.ch/kapralov/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'M Kapralov'});"
                           >Kapralov</a>, <a href='https://di.ku.dk/english/staff/?pure=en/persons/493157'
                           onclick="gtag('event', 'coauthor', {'event_label': 'J Knudsen'});"
                           >Knudsen</a>, <a href='https://www.itu.dk/people/pagh/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'R Pagh'});"
                           >Pagh</a>, <a href='http://www.cs.cmu.edu/~avelingk/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'A Velingker'});"
                           >Velingker</a>, <a href='http://www.cs.cmu.edu/~dwoodruf/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'D Woodruff'});"
                           >Woodruff</a>, <a href='https://people.epfl.ch/amir.zandieh'
                           onclick="gtag('event', 'coauthor', {'event_label': 'A Zandieh'});"
                           >Zandieh</a>
                  </span>
               </div>
               <div class='abstract'><p>
Kernel methods are fundamental tools in machine learning that allow detection of non-linear dependencies between data without explicitly constructing feature vectors in high dimensional spaces. A major disadvantage of kernel methods is their poor scalability: primitives such as kernel PCA or kernel ridge regression generally take prohibitively large quadratic space and (at least) quadratic time, as kernel matrices are usually dense. Some methods for speeding up kernel linear algebra are known, but they all invariably take time exponential in either the dimension of the input point set (e.g., fast multipole methods suffer from the curse of dimensionality) or in the degree of the kernel function.
</p><p>
Oblivious sketching has emerged as a powerful approach to speeding up numerical linear algebra over the past decade, but our understanding of oblivious sketching solutions for kernel matrices has remained quite limited, suffering from the aforementioned exponential dependence on input parameters. Our main contribution is a general method for applying sketching solutions developed in numerical linear algebra over the past decade to a tensoring of data points without forming the tensoring explicitly. This leads to the first oblivious sketch for the polynomial kernel with a target dimension that is only polynomially dependent on the degree of the kernel function, as well as the first oblivious sketch for the Gaussian kernel on bounded datasets that does not suffer from an exponential dependence on the dimensionality of input data points.
</p>
</div>
            </li><li class="toggle-item featured"
                  id='paper-lasvegas'>
               <div class='shown'>
                  <span class='files'>[<a href='http://arxiv.org/abs/1704.02054'
                        onclick="gtag('event', 'download', {'event_label': 'download_lasvegas_arxiv'});"
                        >arxiv</a>]  [<a href='papers/lasvegas.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_lasvegas_pdf'});"
                        >pdf</a>]  [<a href='https://docs.google.com/presentation/d/1HgNCrDFdIZ_oh2RRedmd1qOHgWxk74HSkUCMGcuUbP8/edit'
                        onclick="gtag('event', 'download', {'event_label': 'download_lasvegas_slides'});"
                        >slides</a>]</span>

                  <span class='year'>FOCS
                  2017
                     —
                     <span class="comment">Updated Jun 2018</span></span>

                  
                  <span class='title'>Optimal Las Vegas Locality&nbsp;Sensitive&nbsp;Data&nbsp;Structures</span>
                  

                  <span class='authors'>
                  TA
                  </span>
               </div>
               <div class='abstract'><p>
We show that approximate similarity (near neighbour) search can be solved in high dimensions with performance matching state of the art (data independent) Locality Sensitive Hashing, but with a guarantee of no false negatives.
Specifically we give two data structures for common problems.
For c-approximate near neighbour in Hamming space, for which we get query time dn<sup>1/c+o(1)</sup> and space dn<sup>1+1/c+o(1)</sup> matching that of [Indyk and Motwani, 1998] and answering a long standing open question from [Indyk, 2000a] and [Pagh, 2016] in the affirmative.
For (s<sub>1</sub>,s<sub>2</sub>)-approximate Jaccard similarity we get query time d<sup>2</sup>n<sup>ρ+o(1)</sup> and space d<sup>2</sup>n<sup>1+ρ+o(1)</sup>, ρ = <sup>log(1+s<sub>1</sub>)/(2s<sub>1</sub>)</sup>&frasl;<sub>log(1+s<sub>2</sub>)/(2s<sub>2</sub>)</sub>, when sets have equal size, matching the performance of [Pagh and Christiani, 2017].
</p>

<p>
We use space partitions as in classic LSH, but construct these using a combination of brute force, tensoring and splitter functions à la [Naor et al., 1995].
We also show two dimensionality reduction lemmas with 1-sided error.
</p>
</div>
            </li><li class="toggle-item "
                  id='paper-output-sensitive'>
               <div class='shown'>
                  <span class='files'>[<a href='http://arxiv.org/abs/1605.02673'
                        onclick="gtag('event', 'download', {'event_label': 'download_output-sensitive_arxiv'});"
                        >arxiv</a>]  [<a href='papers/output-sensitive-lsh-for-knn.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_output-sensitive_pdf'});"
                        >pdf</a>]  [<a href='https://docs.google.com/presentation/d/1UOFCN1Eujr4sCQdYqdwn_8D8pNCJHEyzw9Yd_BW6bh4'
                        onclick="gtag('event', 'download', {'event_label': 'download_output-sensitive_slides'});"
                        >slides</a>]</span>

                  <span class='year'>SODA
                  2017</span>

                  
                  <span class='title'>Parameter-free Locality‑Sensitive Hashing for Spherical&nbsp;Range&nbsp;Reporting</span>
                  

                  <span class='authors'>
                  TA, <a href='http://itu.dk/people/maau/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'M Aumüller'});"
                           >M Aumüller</a>, <a href='https://www.itu.dk/people/pagh/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'R Pagh'});"
                           >R Pagh</a>
                  </span>
               </div>
               <div class='abstract'><p>
We present a data structure for <i>spherical range reporting</i> on a point set S, i.e., reporting all points in S that lie within radius r of a given query point q. Our solution builds upon the Locality-Sensitive Hashing (LSH) framework of Indyk and Motwani, which represents the asymptotically best solutions to near neighbor problems in high dimensions. While traditional LSH data structures have several parameters whose optimal values depend on the distance distribution from q to the points of S, our data structure is parameter-free, except for the space usage, which is configurable by the user. Nevertheless, its expected query time basically matches that of an LSH data structure whose parameters have been <i>optimally chosen for the data and query</i> in question under the given space constraints. In particular, our data structure provides a smooth trade-off between hard queries (typically addressed by standard LSH) and easy queries such as those where the number of points to report is a constant fraction of S, or where almost all points in S are far away from the query point. In contrast, known data structures fix LSH parameters based on certain parameters of the input alone.
</p>
<p>
The algorithm has expected query time bounded by O(t(n/t)^ρ), where t is the number of points to report and ρ∈(0,1) depends on the data distribution and the strength of the LSH family used. We further present a parameter-free way of using multi-probing, for LSH families that support it, and show that for many such families this approach allows us to get expected query time close to O(n^ρ+t), which is the best we can hope to achieve using LSH. The previously best running time in high dimensions was Ω(tn^ρ). For many data distributions where the intrinsic dimensionality of the point set close to q is low, we can give improved upper bounds on the expected query time.
</p>
</div>
            </li><li class="toggle-item featured"
                  id='paper-mips'>
               <div class='shown'>
                  <span class='files'>[<a href='http://arxiv.org/abs/1510.02824'
                        onclick="gtag('event', 'download', {'event_label': 'download_mips_arxiv'});"
                        >arxiv</a>]  [<a href='papers/mips.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_mips_pdf'});"
                        >pdf</a>]  [<a href='https://docs.google.com/presentation/d/1y_BZ5Ctyn67Vam8rWzrskMkrkc-yIelCQsFLz1g4_bM'
                        onclick="gtag('event', 'download', {'event_label': 'download_mips_slides'});"
                        >slides</a>]</span>

                  <span class='year'>PODS
                  2016</span>

                  
                  <span class='title'>On the Complexity of Inner&nbsp;Product&nbsp;Similarity&nbsp;Join</span>
                  

                  <span class='authors'>
                  TA, <a href='https://www.itu.dk/people/pagh/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'R Pagh'});"
                           >R Pagh</a>, <a href='http://www.ilyaraz.org/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'I Razenshteyn'});"
                           >I Razenshteyn</a>, <a href='http://www.dei.unipd.it/~silvestri/'
                           onclick="gtag('event', 'coauthor', {'event_label': 'F Silvestri'});"
                           >F Silvestri</a>
                  </span>
               </div>
               <div class='abstract'><p>
A number of tasks in classification, information retrieval, recommendation systems, and record linkage reduce to the core problem of inner product similarity join (IPS join): identifying pairs of vectors in a collection that have a sufficiently large inner product. IPS join is well understood when vectors are normalized and some approximation of inner products is allowed. However, the general case where vectors may have any length appears much more challenging. Recently, new upper bounds based on asymmetric locality-sensitive hashing (ALSH) and asymmetric embeddings have emerged, but little has been known on the lower bound side. In this paper we initiate a systematic study of inner product similarity join, showing new lower and upper bounds. Our main results are: 
<br/>
* Approximation hardness of IPS join in subquadratic time, assuming the strong exponential time hypothesis. 
<br/>* New upper and lower bounds for (A)LSH-based algorithms. In particular, we show that asymmetry can be avoided by relaxing the LSH definition to only consider the collision probability of distinct elements. 
<br/>* A new indexing method for IPS based on linear sketches, implying that our hardness results are not far from being tight. 
</p>
<p>Our technical contributions include new asymmetric embeddings that may be of independent interest. At the conceptual level we strive to provide greater clarity, for example by distinguishing among signed and unsigned variants of IPS join and shedding new light on the effect of asymmetry.
</P
</div>
            </li></ul>
      
         <h2>Manuscripts</h2>
         <ul class="publications"><li class="toggle-item "
                  id='paper-tensorsketch2'>
               <div class='shown'>
                  <span class='files'>[<a href='https://arxiv.org/abs/1909.01821'
                        onclick="gtag('event', 'download', {'event_label': 'download_tensorsketch2_arxiv'});"
                        >arxiv</a>]  [<a href='papers/tensorsketch2.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_tensorsketch2_pdf'});"
                        >pdf</a>]</span>

                  <span class='year'>
                  2019
                     —
                     <span class="comment">Merged into "Oblivious Sketching of High‑Degree Polynomial Kernels"</span></span>

                  
                  <span class='title'>Almost Optimal Tensor Sketch</span>
                  

                  <span class='authors'>
                  TA, <a href='https://di.ku.dk/english/staff/?pure=en/persons/493157'
                           onclick="gtag('event', 'coauthor', {'event_label': 'J Knudsen'});"
                           >J Knudsen</a>
                  </span>
               </div>
               <div class='abstract'>We construct a structured Johnson Lindenstrauss transformation that can be applied to simple tensors on the form  x = x<sup>(1)</sup> ⊗ ... ⊗ x<sup>(c)</sup> ∈ ℝ<sup>dᶜ</sup>  in time nearly c⋅d.
That is, exponentially faster than writing out the Kronecker product and then mapping down.

These matrices, M, which preserves the norm of any x ∈ ℝ<sup>dᶜ</sup>, such that  |‖Mx‖₂ - ‖x‖₂| < ε  with probability  1-δ , can be taken to have just  Õ(c² ε⁻² (log1/δ)³)  rows.
This is within  c² (log 1/δ)²  of optimal for any JL matrix [Larsen & Nelson], and improves upon earlier 'Tensor Sketch' constructions by Pagh and Pham, which used  Õ(3ᶜ ε⁻² δ⁻¹)  rows, by an exponential amount in both  c  and  δ⁻² .

It was shown by Avron, Nguyen and Woodruff that Tensor Sketch is a subspace embedding.
This has a large number of applications, such as guaranteeing the correctness of kernel-linear regression performed directly on the reduced vectors.
We show that our construction is a subspace embedding too, improving again upon the exponential dependency on  c  and  δ⁻¹ , enabling sketching of much higher order polynomial kernels, such as Taylor approximations to the ubiquitous Gaussian radial basis function.

Technically, we construct our matrix  M  such that  M(x ⊗ y) = Tx ∘ T'y  where  ∘  is the Hadamard (element-wise) product and  T  and  T'  support fast matrix-vector multiplication ala [Ailon Chazelle].
To analyze the behavior of  Mx  on non-simple  x , we show a higher order version of Khintchine's inequality, related to the higher order Gaussian chaos analysis by Latała.
Finally we show that such sketches can be combined recursively, in a way that doesn't increase the dependency on  c  by much.
</div>
            </li><li class="toggle-item "
                  id='paper-verification'>
               <div class='shown'>
                  <span class='files'>[<a href='papers/verification.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_verification_pdf'});"
                        >pdf</a>]</span>

                  <span class='year'>
                  2017</span>

                  
                  <span class='title'>It is NP-hard to verify an LSF on the sphere</span>
                  

                  <span class='authors'>
                  TA
                  </span>
               </div>
               <div class='abstract'>We show a reduction from verifying that an LSF family `covers` the sphere, in the sense of Las Vegas LSF, to 3-sat.</div>
            </li><li class="toggle-item "
                  id='paper-minhash'>
               <div class='shown'>
                  <span class='files'>[<a href='papers/minhash.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_minhash_pdf'});"
                        >pdf</a>]  [<a href='https://docs.google.com/presentation/d/1oT-L5EON7ZCVScuYRoMzVHxf7x2Y6cig8deQXMmpP0I/edit?usp=sharing'
                        onclick="gtag('event', 'download', {'event_label': 'download_minhash_slides'});"
                        >slides</a>]</span>

                  <span class='year'>
                  2017
                     —
                     <span class="comment">Master thesis</span></span>

                  
                  <span class='title'>Minhash without false negatives</span>
                  

                  <span class='authors'>
                  TA
                  </span>
               </div>
               <div class='abstract'>We consider efficient combinatorial constructions, that allow us to partly derandomize data-structures using the locality sensitive framework of Indyk and Motwani (FOCS '98).
In particular our constructions allow us to make Zero-Error Probabilistic Polynomial Time (ZPP) analogues of two state of the art algorithms for `Approximate Set Similarity':

This data-structure problem deals with storing a collection  X  of sets such that given a query set  q  for which there exists  x ∈ P  with  |q ∩ x|/|q ∪ x| >= s_1 , the data structures return  x'∈ P  with  |q ∩ x'|/|q ∪ x'|\ge s_2 .
The first algorithm by Broder et al.introduced the famous `minhash' function, which in the locality sensitive framework yields an  n^{ρ_b}  time,  n^{1+ρ_b}  space data structure for  ρ_b=(log1/s_1)/(log1/s_2) .
The second by Christiani et al.~ gives an  n^{ρ_c}  time  n^{1+ρ_c}  space data-structure for  ρ_c=(\log2s_1/(1+s_1))/(\log2s_2/(1+s_2)) .

Both algorithms use Monte Carlo randomization, but we show that this is not necessary, at least up to  n^{o(1)}  factors.
This settles an open problem from Arasu et al and Pagh asking whether locality sensitive data-structures could be made _exact_ or _without false negatives_ other than for hamming distance, and whether a performance gap was needed in the exponent.

The main approach in the thesis is to replace the `locality sensitive hash functions' or `space partitions' with `combinatorial design'.
We show that many such designs can be constructed efficiently with the `multi-splitters' introduced by Alon et al.
We further show that careful constructions of such designs can be efficiently decoded.

We also investigate upper and lower bounds on combinatorial analogues of the minhash algorithm.
This is related to the existence of small, approximate minwise hashing families under  l_∞  distance.
</div>
            </li><li class="toggle-item "
                  id='paper-tails'>
               <div class='shown'>
                  <span class='files'>[<a href='papers/tails.pdf'
                        onclick="gtag('event', 'download', {'event_label': 'download_tails_pdf'});"
                        >pdf</a>]</span>

                  <span class='year'>
                  2017</span>

                  
                  <span class='title'>Asymptotic Tail Bounds and Applications</span>
                  

                  <span class='authors'>
                  TA
                  </span>
               </div>
               <div class='abstract'>In the field of Computer Science, the Chernoff bound is an extremely useful found bounding the error probabilities of various algorithms. Chernoff gives an exponentially decaying upper bound on the probability that a sum of independent random variables is many standard deviations away from its expectation.
However sometimes we need more than an upper bound, and we need bounds that are tight within a constant factor or better. (There is a fairly standard tail lower bound, but it deviates
 from Chernoff by a factor of $\sqrt n$.)
In this project I will explore and derive multiple upper and lower bounds for Chernoff using methods ranging from geometric series and generating functions to saddlepoint approximations and laplace approximation. All these results will be known, but they don’t seem have a good exposition in Computer Science.
The reason also to consider more simple methods is to help an intuition for deriving similar bounds for different problems. In particular I will derive a tight bound for the size of the intersection between two hamming balls, which does not seem to exist in the literature.
I will use the formulas to answer whether algorithms exists for the following problems: Locality Sensitive Filters in hamming space with limited use of random bits (as opposed to current methods, requiring gaussian samples), LSF with improved performance for low dimensional spaces. (dimension < 2 log n) Linear space bit sampling LSH, which I have previously partially analyzed, but only in a different context, in which a full analysis was not necessary.
</div>
            </li></ul>
      

      <h2>Teaching</h2>
      <ul><li>
            <a href='teaching/pcpp2019'>Practical Concurrent and Parallel Programming</a> - 2019.
            <p>MSc course on correct and efficient concurrent and parallel software, primarily using Java, on standard shared-memory multicore hardware.</p>
         </li></ul>


      <h2>Media</h2>
      <ul><li><a href='http://www.stibo.com/da/2016/08/26/the-stibo-foundation-supports-it-talents/'>Stibo</a> &mdash; August 2016.
            "The Stibo-Foundation supports IT-talents."
            </li><li><a href='http://www.pressreader.com/australia/linux-format/20151222/282802125292910'>Linux Format</a> &mdash; January 2016.
            "Python: Sunfish chess engine."
            <a href='papers/sunfish.pdf'
                  onclick="dataLayer.push({'event': 'downloadmedia_pdf'});"
                  >(pdf)</a></li><li><a href='http://www.computerworld.dk/art/234196'>Computerworld</a> &mdash; June 2015.
            "The National Team at the Programming World Cup."
            </li><li><a href='https://www.computerworld.dk/art/228544/her-er-danmarks-tre-bedste-programmoerer'>Computerworld</a> &mdash; October 2013.
            "Denmark's Three Greatest Programmers."
            </li></ul>

      <h2>Code</h2>
      <ul>
         <li><a href='https://pychess.github.io/'>PyChess</a> &mdash; a chess engine and Internet chess client
            &mdash; <a href='https://pychess.org/'>online version</a>
         </li>
         <li><a href='https://github.com/thomasahle/sunfish'>Sunfish</a> &mdash; a minimalist chess engine &mdash;
            <a href='https://lichess.org/@/sunfish-engine'>play at Lichess</a>
            </li>
         <li><a href='https://github.com/thomasahle/numberlink'>numberlink</a> &mdash; a generator and a fast solver for numberlink puzzles</li>
            &mdash;
            <a href='https://numberlinks.puzzlebaron.com/'>play at Puzzle Baron</a>
         <li><a href='https://github.com/thomasahle/codenames'>codenames</a> &mdash; an AI that plays Codenames using Glove vectors.
         <li><a href='https://github.com/thomasahle/fastchess'>fastchess</a> &mdash; an experiment into using the FastText library to play chess.
         <li><a href='https://github.com/thomasahle/mtime'>mtime</a> &mdash; helps managing the ITU time management</li>
      </ul>

      <h2>Other</h2>
      <ul>
         <li>Memrise <a href='https://www.memrise.com/course/44645/500-most-common-danish-words/'>course for learning Danish</a> through the most common 500 words.</li>
      </ul>

   </div>
   <div id='side'>
      <img src='static/potrait.jpg' alt='A photo of me' id='me' />
      <h3>Coauthors</h3>
      <ul><li><a href='http://itu.dk/people/maau/'>Martin Aumüller</a></li><li><a href='https://theory.epfl.ch/kapralov/'>Michael Kapralov</a></li><li><a href='https://di.ku.dk/english/staff/?pure=en/persons/493157'>Jakob Bæk Tejs Knudsen</a></li><li><a href='https://www.itu.dk/people/pagh/'>Rasmus Pagh</a></li><li><a href='http://www.ilyaraz.org/'>Ilya Razenshteyn</a></li><li><a href='http://www.dei.unipd.it/~silvestri/'>Francesco Silvestri</a></li><li><a href='http://hjemmesider.diku.dk/~mthorup/'>Mikkel Thorup</a></li><li><a href='http://www.cs.cmu.edu/~avelingk/'>Ameya Velingker</a></li><li><a href='http://www.cs.cmu.edu/~dwoodruf/'>David P. Woodruff</a></li><li><a href='https://people.epfl.ch/amir.zandieh'>Amir Zandieh</a></li></ul>

      <h3>Contact</h3>
      <ul>
         <li><a href='/blog' title='My blog'>Blog</a></li>
         <li><a href='https://twitter.com/thomasahle'>Twitter</a></li>
         <li>Email: thdy@itu.dk</li>
         <!--<li><a href='statement.pdf'>Academic Statement</a></li>-->
         <li><a href='cv.pdf' >CV</a></li>
         <li><a href='https://dblp1.uni-trier.de/pers/hd/a/Ahle:Thomas_D='>DBLP</a></li>
         <li><a href='https://scholar.google.dk/citations?user=aRiVoYgAAAAJ'>Google Scholar</a></li>
         <li><a href='https://linkedin.com/in/thomasahle'>LinkedIn</a></li>
         <li><a href='https://github.com/thomasahle'>GitHub</a></li>
         <li><a href='https://orcid.org/0000-0001-9747-0479'>ORCiD</a></li>
      </ul>

      <a class="twitter-timeline"
         href="https://twitter.com/thomasahle"
         data-tweet-limit="5"
         data-chrome="nofooter, noscrollbar"
         data-dnt="true"
         >Tweets</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
   </div>
</body>
</html>

